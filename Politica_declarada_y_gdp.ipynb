{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "_98_f6aN8Zem"
      },
      "outputs": [],
      "source": [
        "latinobarometro = pd.read_stata('/content/Latinobarometro_2020_Esp_Stata_v1_0.dta')\n",
        "# Limpiar espacios y normalizar mayúsculas/minúsculas\n",
        "latinobarometro['idenpa_clean'] = latinobarometro['idenpa'].str.strip().str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversion = {\n",
        "    \"No muy satisfecho\": 1,\n",
        "    \"Para nada satisfecho\": 2,\n",
        "    \"Bastante satisfecho\": 3,\n",
        "    \"Muy satisfecho\": 4\n",
        "}\n",
        "\n",
        "# Reemplazar valores en la columna P1ST\n",
        "latinobarometro[\"felicidad\"] = latinobarometro[\"p1st\"].map(conversion)"
      ],
      "metadata": {
        "id": "fPGsgnsy9_Pp"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Diccionario de conversión explícita\n",
        "conversion = {\n",
        "    \"derecha\": 10,\n",
        "    \"izquierda\": 0,\n",
        "    \"Ninguno\": np.nan,\n",
        "    \"No contesta\": np.nan,\n",
        "    \"No sabe\": np.nan,\n",
        "    97: np.nan,\n",
        "    99: np.nan,\n",
        "    \"97\": np.nan,\n",
        "    \"99\": np.nan\n",
        "}\n",
        "\n",
        "def convertir(val):\n",
        "    # Si el valor está en el diccionario, usarlo\n",
        "    if val in conversion:\n",
        "        return conversion[val]\n",
        "\n",
        "    # Si es numérico y no es 97/99, devolverlo tal cual\n",
        "    try:\n",
        "        # intentar convertir a número\n",
        "        num = float(val)\n",
        "        # si es 97 o 99, poner NaN igual por seguridad\n",
        "        if num in [97, 99]:\n",
        "            return np.nan\n",
        "        return num\n",
        "    except:\n",
        "        # cualquier string que no esté en el dict lo dejamos como está\n",
        "        return val\n",
        "\n",
        "latinobarometro[\"escala\"] = latinobarometro[\"p18st\"].apply(convertir)"
      ],
      "metadata": {
        "id": "P-4Rj6D8-Owl"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Reemplazar strings '#NA' por NaN\n",
        "latinobarometro['felicidad'] = latinobarometro['felicidad'].replace(\"#NA\", np.nan)\n",
        "latinobarometro['escala'] = latinobarometro['escala'].replace(\"#NA\", np.nan)\n",
        "\n",
        "# Filtrar filas válidas (sin NaN)\n",
        "df = latinobarometro[['felicidad', 'escala']].dropna()\n",
        "\n",
        "# Calcular correlación de Pearson\n",
        "corr, pval = pearsonr(df['felicidad'].astype(float), df['escala'].astype(float))\n",
        "\n",
        "print(f\"Correlation (Pearson): {corr:.4f}\")\n",
        "print(f\"P-value: {pval:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6twQc2CM8wS3",
        "outputId": "48772d63-01c6-4b9c-a644-e63501378dff"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation (Pearson): 0.0152\n",
            "P-value: 0.0537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "df = latinobarometro.copy()\n",
        "\n",
        "# Asegurar que la escala es numérica (ignorar errores)\n",
        "df[\"escala\"] = pd.to_numeric(df[\"escala\"], errors=\"coerce\")\n",
        "\n",
        "# Asegurar que felicidad es numérica\n",
        "df[\"felicidad\"] = pd.to_numeric(df[\"felicidad\"], errors=\"coerce\")\n",
        "\n",
        "# --- 1) Polarización por ciudad: desviación estándar ---\n",
        "polar_ciudad = df.groupby(\"ciudad\")[\"escala\"].std().reset_index()\n",
        "polar_ciudad.columns = [\"ciudad\", \"polarizacion_sd\"]\n",
        "\n",
        "\n",
        "# --- 2) (Opcional) Polarización por extremos ---\n",
        "def extremos(x):\n",
        "    x = x.dropna()\n",
        "    if len(x) == 0:\n",
        "        return np.nan\n",
        "    return ((x < 2) | (x > 8)).mean()  # proporción en extremos\n",
        "\n",
        "polar_ciudad[\"polarizacion_extremos\"] = df.groupby(\"ciudad\")[\"escala\"].apply(extremos).values\n",
        "\n",
        "\n",
        "# --- 3) Felicidad promedio por ciudad ---\n",
        "felicidad_ciudad = df.groupby(\"ciudad\")[\"felicidad\"].mean().reset_index()\n",
        "felicidad_ciudad.columns = [\"ciudad\", \"felicidad_prom\"]\n",
        "\n",
        "# Merge\n",
        "merged = felicidad_ciudad.merge(polar_ciudad, on=\"ciudad\", how=\"left\").dropna()\n",
        "\n",
        "# --- 4) Correlación: polarización vs felicidad promedio ---\n",
        "corr_sd, p_sd = pearsonr(merged[\"felicidad_prom\"], merged[\"polarizacion_sd\"])\n",
        "corr_ext, p_ext = pearsonr(merged[\"felicidad_prom\"], merged[\"polarizacion_extremos\"])\n",
        "\n",
        "print(\"Correlación felicidad promedio ~ polarización (SD):\", corr_sd, \"p=\", p_sd)\n",
        "print(\"Correlación felicidad promedio ~ polarización (extremos):\", corr_ext, \"p=\", p_ext)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JKo0jCgAYTr",
        "outputId": "f19ce699-0c27-47a8-9175-07e243a06020"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2375488557.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  polar_ciudad = df.groupby(\"ciudad\")[\"escala\"].std().reset_index()\n",
            "/tmp/ipython-input-2375488557.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  polar_ciudad[\"polarizacion_extremos\"] = df.groupby(\"ciudad\")[\"escala\"].apply(extremos).values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlación felicidad promedio ~ polarización (SD): 0.21423441451780467 p= 2.381618926176736e-14\n",
            "Correlación felicidad promedio ~ polarización (extremos): 0.217459784578625 p= 9.498863056580367e-15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2375488557.py:29: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  felicidad_ciudad = df.groupby(\"ciudad\")[\"felicidad\"].mean().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "# Filtrar datos válidos\n",
        "df = latinobarometro[['idenpa','felicidad','escala']].replace(\"#NA\", np.nan).dropna()\n",
        "\n",
        "# Función para porcentaje de extremos ideológicos\n",
        "def extremos(x):\n",
        "    return ((x == 0) | (x == 10)).mean()\n",
        "\n",
        "# Polarización por país\n",
        "polar_pais = df.groupby(\"idenpa\", observed=False)[\"escala\"].agg(\n",
        "    polar_sd = 'std',            # dispersión ideológica\n",
        "    polar_ext = extremos         # % extremos ideológicos\n",
        ").reset_index()\n",
        "\n",
        "# Felicidad promedio por país\n",
        "felic_pais = df.groupby(\"idenpa\", observed=False)[\"felicidad\"].mean().reset_index(name=\"felicidad_prom\")\n",
        "\n",
        "# Merge\n",
        "merged = polar_pais.merge(felic_pais, on=\"idenpa\")\n",
        "\n",
        "# Calcular correlaciones\n",
        "corr_sd, p_sd = pearsonr(merged[\"felicidad_prom\"], merged[\"polar_sd\"])\n",
        "corr_ext, p_ext = pearsonr(merged[\"felicidad_prom\"], merged[\"polar_ext\"])\n",
        "\n",
        "print(\"Correlación felicidad país ~ polarización (SD):\", corr_sd, \"p=\", p_sd)\n",
        "print(\"Correlación felicidad país ~ polarización (extremos):\", corr_ext, \"p=\", p_ext)\n",
        "print(\"\\nTabla de países:\")\n",
        "print(merged)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJgVrvrCjRG",
        "outputId": "74d90b00-c0c5-40e1-8cdd-6c88363a607a"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlación felicidad país ~ polarización (SD): 0.6117420764906453 p= 0.006977273056358408\n",
            "Correlación felicidad país ~ polarización (extremos): 0.6192812222890958 p= 0.006131916032067055\n",
            "\n",
            "Tabla de países:\n",
            "              idenpa  polar_sd  polar_ext  felicidad_prom\n",
            "0          Argentina  2.377213   0.128041        2.719590\n",
            "1            Bolivia  2.619663   0.177312        2.591992\n",
            "2             Brasil  2.877425   0.204198        2.669847\n",
            "3              Chile  2.116546   0.068413        2.521106\n",
            "4           Colombia  2.680660   0.173585        3.266981\n",
            "5         Costa Rica  2.833996   0.223289        3.232893\n",
            "6    Rep. Dominicana  3.762789   0.515317        3.253829\n",
            "7            Ecuador  3.027315   0.287596        2.971460\n",
            "8        El Salvador  2.764292   0.247104        3.181467\n",
            "9          Guatemala  3.381924   0.388451        3.309711\n",
            "10          Honduras  3.573034   0.420526        3.117647\n",
            "11           MÃ©xico  2.645520   0.189071        3.162842\n",
            "12         Nicaragua  3.801090   0.510015        3.110940\n",
            "13           PanamÃ¡  3.271184   0.354839        3.166852\n",
            "14          Paraguay  2.548594   0.154394        2.704276\n",
            "15             PerÃº  2.575527   0.164122        2.826336\n",
            "16           Uruguay  3.154891   0.281362        3.056452\n",
            "17         Venezuela  3.098697   0.287402        2.824803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ourworldindata.org/grapher/gdp-per-capita-worldbank.csv?v=1&csvType=filtered&useColumnShortNames=false&tab=table&overlay=download-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojfMlQd9IN-Q",
        "outputId": "da394595-14c9-4b33-bda5-285b892b75d3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-04 18:53:38--  https://ourworldindata.org/grapher/gdp-per-capita-worldbank.csv?v=1\n",
            "Resolving ourworldindata.org (ourworldindata.org)... 172.66.164.52, 104.20.21.76, 2606:4700:10::6814:154c, ...\n",
            "Connecting to ourworldindata.org (ourworldindata.org)|172.66.164.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222370 (217K) [text/csv]\n",
            "Saving to: ‘gdp-per-capita-worldbank.csv?v=1.3’\n",
            "\n",
            "gdp-per-capita-worl 100%[===================>] 217.16K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-04 18:53:38 (19.3 MB/s) - ‘gdp-per-capita-worldbank.csv?v=1.3’ saved [222370/222370]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdp=pd.read_csv('/content/gdp-per-capita-worldbank.csv?v=1')"
      ],
      "metadata": {
        "id": "SUB3yR3gIl3C"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def normalize(s):\n",
        "    return (unicodedata.normalize('NFKD', s)\n",
        "            .encode('ascii', 'ignore')\n",
        "            .decode('utf-8')\n",
        "            .upper()\n",
        "            .strip())\n",
        "\n",
        "latinobarometro['idenpa_norm'] = latinobarometro['idenpa_clean'].apply(normalize)\n"
      ],
      "metadata": {
        "id": "_bWo0HW0LRDC"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    \"ARGENTINA\": \"Argentina\",\n",
        "    \"BOLIVIA\": \"Bolivia\",\n",
        "    \"BRASIL\": \"Brazil\",\n",
        "    \"COLOMBIA\": \"Colombia\",\n",
        "    \"COSTA RICA\": \"Costa Rica\",\n",
        "    \"CHILE\": \"Chile\",\n",
        "    \"ECUADOR\": \"Ecuador\",\n",
        "    \"EL SALVADOR\": \"El Salvador\",\n",
        "    \"GUATEMALA\": \"Guatemala\",\n",
        "    \"HONDURAS\": \"Honduras\",\n",
        "    \"MEXICO\": \"Mexico\",\n",
        "    \"NICARAGUA\": \"Nicaragua\",\n",
        "    \"PANAMA\": \"Panama\",\n",
        "    \"PARAGUAY\": \"Paraguay\",\n",
        "    \"PERU\": \"Peru\",\n",
        "    \"REP. DOMINICANA\": \"Dominican Republic\",\n",
        "    \"URUGUAY\": \"Uruguay\",\n",
        "    \"VENEZUELA\": \"Venezuela\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "GF577bn2MdQ8"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latinobarometro['pais_eng'] = latinobarometro['idenpa_norm'].map(mapping)"
      ],
      "metadata": {
        "id": "rNsMtE32MehY"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import difflib\n",
        "import pandas as pd\n",
        "\n",
        "# --- helper: normalizar nombres ---\n",
        "def normalize_name(s):\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "    s = s.strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "# --- helper: intentar arreglar mojibake latin1->utf-8 ---\n",
        "def fix_mojibake(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    s = str(s)\n",
        "    # si no contiene la secuencia típica de mojibake, devolvemos\n",
        "    if \"Ã\" not in s and \"Â\" not in s:\n",
        "        return s\n",
        "    try:\n",
        "        candidate = s.encode(\"latin1\").decode(\"utf-8\")\n",
        "    except Exception:\n",
        "        return s\n",
        "    # elegimos el que tenga más letras/espacios (heurística simple)\n",
        "    def score(u):\n",
        "        return sum(1 for c in u if c.isalpha() or c.isspace())\n",
        "    return candidate if score(candidate) > score(s) else s\n",
        "\n",
        "# --- aplica reparación y normalización a merged y a gdp_latest.pais (por si acaso) ---\n",
        "merged_df = merged.copy()\n",
        "gdp_latest = gdp_latest.copy()\n",
        "\n",
        "merged_df[\"idenpa_fix\"] = merged_df[\"idenpa\"].apply(fix_mojibake)\n",
        "merged_df[\"idenpa_norm\"] = merged_df[\"idenpa_fix\"].apply(normalize_name)\n",
        "\n",
        "gdp_latest[\"pais_fix\"] = gdp_latest[\"pais\"].apply(fix_mojibake)\n",
        "gdp_latest[\"pais_norm\"] = gdp_latest[\"pais_fix\"].apply(normalize_name)\n",
        "\n",
        "gdp_name_set = set(gdp_latest[\"pais_norm\"].unique())\n",
        "\n",
        "# --- mapa manual (agregá/edita si hace falta) ---\n",
        "mapa_paises = {\n",
        "    \"argentina\": \"Argentina\",\n",
        "    \"bolivia\": \"Bolivia\",\n",
        "    \"brasil\": \"Brazil\",\n",
        "    \"chile\": \"Chile\",\n",
        "    \"colombia\": \"Colombia\",\n",
        "    \"costa rica\": \"Costa Rica\",\n",
        "    \"rep. dominicana\": \"Dominican Republic\",\n",
        "    \"rep dominicana\": \"Dominican Republic\",\n",
        "    \"republica dominicana\": \"Dominican Republic\",\n",
        "    \"ecuador\": \"Ecuador\",\n",
        "    \"el salvador\": \"El Salvador\",\n",
        "    \"guatemala\": \"Guatemala\",\n",
        "    \"honduras\": \"Honduras\",\n",
        "    \"mexico\": \"Mexico\",\n",
        "    \"méxico\": \"Mexico\",\n",
        "    \"nicaragua\": \"Nicaragua\",\n",
        "    \"panama\": \"Panama\",\n",
        "    \"panamá\": \"Panama\",\n",
        "    \"paraguay\": \"Paraguay\",\n",
        "    \"peru\": \"Peru\",\n",
        "    \"perú\": \"Peru\",\n",
        "    \"uruguay\": \"Uruguay\",\n",
        "    \"venezuela\": \"Venezuela\"\n",
        "}\n",
        "mapa_paises_norm = { normalize_name(k): v for k,v in mapa_paises.items() }\n",
        "\n",
        "# --- primer pase: mapa directo ---\n",
        "merged_df[\"pais_owid\"] = merged_df[\"idenpa_norm\"].map(mapa_paises_norm)\n",
        "\n",
        "# --- segundo pase: fuzzy matching para los que quedan sin mapear ---\n",
        "def fuzzy_lookup_to_owid(norm_name, cutoff=0.60):\n",
        "    if not norm_name:\n",
        "        return None\n",
        "    if norm_name in gdp_name_set:\n",
        "        return gdp_latest.loc[gdp_latest[\"pais_norm\"] == norm_name, \"pais_fix\"].iat[0]\n",
        "    matches = difflib.get_close_matches(norm_name, list(gdp_name_set), n=1, cutoff=cutoff)\n",
        "    if matches:\n",
        "        matched_norm = matches[0]\n",
        "        return gdp_latest.loc[gdp_latest[\"pais_norm\"] == matched_norm, \"pais_fix\"].iat[0]\n",
        "    return None\n",
        "\n",
        "mask_na = merged_df[\"pais_owid\"].isna()\n",
        "for idx in merged_df[mask_na].index:\n",
        "    norm = merged_df.at[idx, \"idenpa_norm\"]\n",
        "    candidate = fuzzy_lookup_to_owid(norm, cutoff=0.60)\n",
        "    merged_df.at[idx, \"pais_owid\"] = candidate\n",
        "\n",
        "# --- mostrar quién quedó sin mapear ---\n",
        "no_map = merged_df[merged_df[\"pais_owid\"].isna()][[\"idenpa\", \"idenpa_fix\", \"idenpa_norm\"]]\n",
        "print(\"Quedaron sin mapear (después de reparación y fuzzy):\")\n",
        "print(no_map.to_string(index=False))\n",
        "\n",
        "# --- para cada no mapeado, mostrar las mejores coincidencias de gdp_latest (n=5) ---\n",
        "if not no_map.empty:\n",
        "    print(\"\\nSugerencias desde gdp_latest para cada no mapeado:\")\n",
        "    for idx in no_map.index:\n",
        "        norm = merged_df.at[idx, \"idenpa_norm\"]\n",
        "        print(f\"\\n{merged_df.at[idx,'idenpa']}  -> normalizado='{norm}'\")\n",
        "        cands = difflib.get_close_matches(norm, list(gdp_name_set), n=5, cutoff=0.4)\n",
        "        if cands:\n",
        "            for c in cands:\n",
        "                display_name = gdp_latest.loc[gdp_latest[\"pais_norm\"] == c, \"pais_fix\"].iat[0]\n",
        "                print(\"   -\", display_name, \" (norm:\", c, \")\")\n",
        "        else:\n",
        "            print(\"   - No se encontraron candidatos cercanos (baja cutoff si querés).\")\n",
        "\n",
        "# --- reconvertir a string y merge final ---\n",
        "merged_df[\"pais_owid\"] = merged_df[\"pais_owid\"].astype(\"string\")\n",
        "gdp_latest[\"pais_fix\"] = gdp_latest[\"pais_fix\"].astype(\"string\")\n",
        "\n",
        "merged_final = merged_df.merge(\n",
        "    gdp_latest[[\"pais_fix\", \"gdp_pc\"]],\n",
        "    left_on=\"pais_owid\",\n",
        "    right_on=\"pais_fix\",\n",
        "    how=\"left\"\n",
        ").drop(columns=[\"pais_fix\", \"idenpa_fix\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6iAuPBvSpyO",
        "outputId": "8982ac4a-bc3b-4161-c421-0deb8186d660"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quedaron sin mapear (después de reparación y fuzzy):\n",
            "Empty DataFrame\n",
            "Columns: [idenpa, idenpa_fix, idenpa_norm]\n",
            "Index: []\n",
            "\n",
            "Primeras filas del resultado:\n",
            "    idenpa  polar_sd  polar_ext  felicidad_prom pais_owid idenpa_norm    gdp_pc\n",
            " Argentina  2.377213   0.128041        2.719590 Argentina   argentina 26547.050\n",
            "   Bolivia  2.619663   0.177312        2.591992   Bolivia     bolivia  9844.276\n",
            "    Brasil  2.877425   0.204198        2.669847    Brazil      brasil 19647.910\n",
            "     Chile  2.116546   0.068413        2.521106     Chile       chile 30182.787\n",
            "  Colombia  2.680660   0.173585        3.266981  Colombia    colombia 18503.670\n",
            "\n",
            "Filas sin gdp_pc tras merge (si aparecen, hay que afinar el mapa):\n",
            "    idenpa pais_owid\n",
            " Venezuela Venezuela\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Subset solo columnas necesarias y drop de filas sin datos\n",
        "df = merged_final[['felicidad_prom', 'polar_ext', 'gdp_pc']].dropna()\n",
        "\n",
        "# Definir X y Y\n",
        "X = df[['polar_ext', 'gdp_pc']]\n",
        "X = sm.add_constant(X)   # agregar constante\n",
        "y = df['felicidad_prom']\n",
        "\n",
        "# Ajustar modelo OLS con errores robustos HC3\n",
        "model = sm.OLS(y, X).fit(cov_type='HC3')\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlp8gq_OVpfX",
        "outputId": "bdb9e5f1-86aa-4e25-fa18-9d87fe552e9b"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:         felicidad_prom   R-squared:                       0.419\n",
            "Model:                            OLS   Adj. R-squared:                  0.336\n",
            "Method:                 Least Squares   F-statistic:                     5.593\n",
            "Date:                Tue, 04 Nov 2025   Prob (F-statistic):             0.0164\n",
            "Time:                        19:29:18   Log-Likelihood:                 3.7467\n",
            "No. Observations:                  17   AIC:                            -1.493\n",
            "Df Residuals:                      14   BIC:                             1.006\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:                  HC3                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          2.5616      0.179     14.332      0.000       2.211       2.912\n",
            "polar_ext      1.3311      0.409      3.252      0.001       0.529       2.133\n",
            "gdp_pc       4.06e-06   5.04e-06      0.805      0.421   -5.82e-06    1.39e-05\n",
            "==============================================================================\n",
            "Omnibus:                        1.593   Durbin-Watson:                   1.597\n",
            "Prob(Omnibus):                  0.451   Jarque-Bera (JB):                1.293\n",
            "Skew:                           0.527   Prob(JB):                        0.524\n",
            "Kurtosis:                       2.153   Cond. No.                     1.82e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
            "[2] The condition number is large, 1.82e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    }
  ]
}